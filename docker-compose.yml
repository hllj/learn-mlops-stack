version: "3"
services:
    prediction_api:
        build: .
        container_name: "inference_container"
        ports:
            - "3499:3499"
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]
